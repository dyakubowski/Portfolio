{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T21:23:00.799766Z","iopub.execute_input":"2022-03-14T21:23:00.800143Z","iopub.status.idle":"2022-03-14T21:23:00.812289Z","shell.execute_reply.started":"2022-03-14T21:23:00.800106Z","shell.execute_reply":"2022-03-14T21:23:00.811341Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# import libraries for loading data and analyzies\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom path import Path\n\n# open folders in zip-files and read files\nmyzip = Path('/kaggle/input/two-sigma-connect-rental-listing-inquiries/sample_submission.csv.zip')\nsample_sub = pd.read_csv(myzip, index_col='listing_id')\n\nto_train = Path('/kaggle/input/two-sigma-connect-rental-listing-inquiries/train.json.zip')\ndata_train = pd.read_json(to_train)\n# set listing indecies as indecies for dataframe\ndata_train.set_index('listing_id', inplace=True)\n\n# and for testing data too\nto_test = Path('/kaggle/input/two-sigma-connect-rental-listing-inquiries/test.json.zip')\ndata_test = pd.read_json(to_test)\ndata_test.set_index('listing_id', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:23:00.834665Z","iopub.execute_input":"2022-03-14T21:23:00.835136Z","iopub.status.idle":"2022-03-14T21:23:05.048926Z","shell.execute_reply.started":"2022-03-14T21:23:00.835098Z","shell.execute_reply":"2022-03-14T21:23:05.047751Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# check if there is null values\ndata_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:23:05.050937Z","iopub.execute_input":"2022-03-14T21:23:05.051506Z","iopub.status.idle":"2022-03-14T21:23:05.120644Z","shell.execute_reply.started":"2022-03-14T21:23:05.051457Z","shell.execute_reply":"2022-03-14T21:23:05.119657Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# look how many rows have values 'low', 'medium' and 'high'\nprint(Counter(data_train.interest_level.values))\n# image barplot to look\nn_count = data_train.interest_level.value_counts()\nplot = sns.barplot(n_count.index, n_count.values)\nplt.setp(plot.get_xticklabels(), rotation=30, fontsize=10)\nplt.title('Distribution of interest_level values')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Values', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:23:05.121832Z","iopub.execute_input":"2022-03-14T21:23:05.122578Z","iopub.status.idle":"2022-03-14T21:23:05.337414Z","shell.execute_reply.started":"2022-03-14T21:23:05.122539Z","shell.execute_reply":"2022-03-14T21:23:05.336440Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# image heatmap imaging correlation link between variables\nf, ax = plt.subplots(figsize=(20, 10))\nsns.heatmap(data_train.corr(), vmin=-1, vmax=1, square=True, cmap='YlGnBu', annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:23:05.339884Z","iopub.execute_input":"2022-03-14T21:23:05.340312Z","iopub.status.idle":"2022-03-14T21:23:05.731932Z","shell.execute_reply.started":"2022-03-14T21:23:05.340265Z","shell.execute_reply":"2022-03-14T21:23:05.731096Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# and built pairplots of distribution values between variables\nthe_strongest_corr = data_train.corr().price.sort_values(ascending=False)\nsns.pairplot(data_train[dict(the_strongest_corr).keys()], size=2.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:23:05.733295Z","iopub.execute_input":"2022-03-14T21:23:05.733537Z","iopub.status.idle":"2022-03-14T21:27:58.047688Z","shell.execute_reply.started":"2022-03-14T21:23:05.733505Z","shell.execute_reply":"2022-03-14T21:27:58.046913Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# the more photos the higher demand on appartament. Let's summarize photos and write it into new variable \ndata_train[\"num_photos\"] = data_train[\"photos\"].apply(len)\n# Let's consider that detail description is good opportunity to sale house or flat. Divide description into words and calculate their count \ndata_train[\"new_description\"] = data_train[\"description\"].apply(lambda x: len(x.split(' ')))\n# in the same way for testing dataframe\ndata_test[\"num_photos\"] = data_test[\"photos\"].apply(len)\ndata_test[\"new_description\"] = data_test[\"description\"].apply(lambda x: len(x.split(' ')))","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:27:58.048815Z","iopub.execute_input":"2022-03-14T21:27:58.049663Z","iopub.status.idle":"2022-03-14T21:27:58.858219Z","shell.execute_reply.started":"2022-03-14T21:27:58.049624Z","shell.execute_reply":"2022-03-14T21:27:58.857163Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# 'features' has all facilities in the flat or the house\ncnt = Counter()\n# choose 10 the most mentioned facilities in training dataframe\nfor feat in data_train.features:\n    feats = set(map(str.lower, feat))  # make all letters lowercase\n    for word in feats:\n        cnt[word] += 1\n    num_most_common = 10\n# prepare list of these facilities to make new variables\nmost_common_feats = [k for k, _ in cnt.most_common(num_most_common)]\nprint(most_common_feats)\n\n# create columns each of these will represent availability of one or the other facility\nfor feat in most_common_feats:\n    # create new column\n    data_train[feat] = 0\n    for i in range(len(data_train['features'])):\n        # 1 if this feature in this flat or house\n        if feat in [s.lower() for s in data_train['features'].iloc[i]]:\n            data_train[feat].iloc[i] = 1\n        # 0 if otherwise\n        else:\n            data_train[feat].iloc[i] = 0\n# the more features the more demand. Make column contains count of features\ndata_train['new_features'] = data_train[\"features\"].apply(len)\n\n# in the same way for testing data\ncnt1 = Counter()\nfor feat in data_test.features:\n    feats = set(map(str.lower, feat))\n    for word in feats:\n        cnt1[word] += 1\n    num_most_common1 = 10\nmost_common_feats1 = [k for k, _ in cnt.most_common(num_most_common1)]\nprint(most_common_feats1)\n\nfor feat in most_common_feats1:\n    data_test[feat] = 0\n    for i in range(len(data_test['features'])):\n        if feat in [s.lower() for s in data_test['features'].iloc[i]]:\n            data_test[feat].iloc[i] = 1\n        else:\n            data_test[feat].iloc[i] = 0\ndata_test['new_features'] = data_test[\"features\"].apply(len)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:27:58.859695Z","iopub.execute_input":"2022-03-14T21:27:58.860022Z","iopub.status.idle":"2022-03-14T21:35:55.934839Z","shell.execute_reply.started":"2022-03-14T21:27:58.859979Z","shell.execute_reply":"2022-03-14T21:35:55.933922Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# import lybrary for date and time\nimport datetime\n\n# let's define how long time listing is publicated on the site\ndata_train['days_listing'] = 0\nfor i in range(len(data_train['created'])):\n    # format date and time to string massive\n    date = datetime.datetime.strptime(data_train['created'].iloc[i], '%Y-%m-%d %H:%M:%S')\n    # current data will be the 13th of March of 2022. Time will be midnight\n    date_now = datetime.datetime.strptime('2022-03-13 00:00:00', '%Y-%m-%d %H:%M:%S')\n    # subtract date of publication from current day\n    total_days = (date_now - date).days\n    # total days after date of publication\n    data_train['days_listing'].iloc[i] = total_days\n\n# the same way for testing data\ndata_test['days_listing'] = 0\nfor i in range(len(data_test['created'])):\n    date = datetime.datetime.strptime(data_test['created'].iloc[i], '%Y-%m-%d %H:%M:%S')\n    date_now = datetime.datetime.strptime('2022-03-13 00:00:00', '%Y-%m-%d %H:%M:%S')\n    total_days = (date_now - date).days\n    data_test['days_listing'].iloc[i] = total_days","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:35:55.936519Z","iopub.execute_input":"2022-03-14T21:35:55.936849Z","iopub.status.idle":"2022-03-14T21:36:54.233262Z","shell.execute_reply.started":"2022-03-14T21:35:55.936807Z","shell.execute_reply":"2022-03-14T21:36:54.232262Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# make copies of training data and testing to save data\ndata = data_train.copy()\ntesting_data = data_test.copy()\n# drop columns on the basic which we created new columns. So we transformed them\ndata = data.drop(['created', 'description', 'photos', 'features'], axis=1)\ntesting_data = testing_data.drop(['created', 'description', 'photos', 'features'], axis=1)\n# look how many values have rest categorical variables (type is 'object')\n# 'interest_level' is variable for prediction. It is not considered\ncategorical = [feature for feature in data.columns if data[feature].dtype == 'object' and feature != 'interest_level']\n# each feature of variable can be in a few cells\nnumber = [len(data[features].unique()) for features in categorical]  # another ones have type 'int' or 'float'\n# image count of features at dataframe\ndata_tuples = list(zip(categorical, number))\ncategorical_data = pd.DataFrame(data_tuples, columns=['Features', 'Number of distinct values'])  # calculate how many values has each categoric variable\ncategorical_data","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:36:54.234784Z","iopub.execute_input":"2022-03-14T21:36:54.236071Z","iopub.status.idle":"2022-03-14T21:36:54.378357Z","shell.execute_reply.started":"2022-03-14T21:36:54.236007Z","shell.execute_reply":"2022-03-14T21:36:54.377217Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# with module 'LabelEncoder' take for categoric features digit values\nfrom sklearn.preprocessing import LabelEncoder\n\nfor c in categorical:\n    label_encoder = LabelEncoder() \n    label_encoder.fit(list(data[c].values)) \n    data[c] = label_encoder.transform(list(data[c].values))\ntraining_data = data.copy()\nfor c in categorical:\n    label_encoder = LabelEncoder() \n    label_encoder.fit(list(testing_data[c].values)) \n    testing_data[c] = label_encoder.transform(list(testing_data[c].values))","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:36:54.382206Z","iopub.execute_input":"2022-03-14T21:36:54.382566Z","iopub.status.idle":"2022-03-14T21:36:56.133192Z","shell.execute_reply.started":"2022-03-14T21:36:54.382523Z","shell.execute_reply":"2022-03-14T21:36:56.132130Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# add column with average price per potentional person (bedroom) (0.125 is epsilon to avoid infinity values)\ntraining_data[\"price_t\"] = training_data[\"price\"] / (training_data[\"bedrooms\"] + 0.125)\n# and total count of bedrooms and bathrooms\ntraining_data[\"room_sum\"] = training_data[\"bedrooms\"] + training_data[\"bathrooms\"]\n# the same way for testing data\ntesting_data[\"price_t\"] = testing_data[\"price\"] / (testing_data[\"bedrooms\"] + 0.125)\ntesting_data[\"room_sum\"] = testing_data[\"bedrooms\"] + testing_data[\"bathrooms\"]\n# Because 'interest_level' is object, make values digits n the such way:\ntraining_data['interest_level'] = training_data['interest_level'].replace({'low': 0, 'medium': 1, 'high': 2})","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:36:56.134521Z","iopub.execute_input":"2022-03-14T21:36:56.134769Z","iopub.status.idle":"2022-03-14T21:36:56.187904Z","shell.execute_reply.started":"2022-03-14T21:36:56.134739Z","shell.execute_reply":"2022-03-14T21:36:56.186854Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# formulate training and testing data. Highlight variable 'interest_level' as estimated\nX_train = training_data.drop(['interest_level'], axis=1)\nX_test = testing_data\ny_train = training_data.interest_level","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:36:56.189652Z","iopub.execute_input":"2022-03-14T21:36:56.190020Z","iopub.status.idle":"2022-03-14T21:36:56.206837Z","shell.execute_reply.started":"2022-03-14T21:36:56.189973Z","shell.execute_reply":"2022-03-14T21:36:56.205545Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# import libraries for making model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\n# use model RandomForestClassifier and fit it\n# divide trainig data into train and test and check them for exactness\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33)\nclf = RandomForestClassifier(n_estimators=1000)\n# fit model\nclf.fit(X_train, y_train)\n# predict values from training dataframe and compare these with original\ny_val_pred = clf.predict_proba(X_val)\nlog_loss(y_val, y_val_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:36:56.208744Z","iopub.execute_input":"2022-03-14T21:36:56.209167Z","iopub.status.idle":"2022-03-14T21:38:25.304356Z","shell.execute_reply.started":"2022-03-14T21:36:56.209117Z","shell.execute_reply":"2022-03-14T21:38:25.303406Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# predict probabilities of interest level for testing data\ny_final = clf.predict_proba(X_test).round(6)\n# make classes for submission and rename keys (for 0 is 'low', for 1 - 'medium', for 2 - 'high')\nlabels_interesting_level = {label: i for i, label in enumerate(clf.classes_)}\nfor_replace = {0: 'low', 1: 'medium', 2: 'high'}\nfor i in labels_interesting_level:\n    if i in for_replace:\n        labels_interesting_level[for_replace[i]] = labels_interesting_level.pop(i)\nlabels_interesting_level","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:38:25.305714Z","iopub.execute_input":"2022-03-14T21:38:25.306055Z","iopub.status.idle":"2022-03-14T21:38:45.368232Z","shell.execute_reply.started":"2022-03-14T21:38:25.305992Z","shell.execute_reply":"2022-03-14T21:38:45.367099Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# create dataframe for predicted values\nsubmission = pd.DataFrame()\ndata_test = data_test.reset_index()\nsubmission[\"listing_id\"] = data_test[\"listing_id\"]\n# write results for 'low', 'medium' and 'high' levels respectively\nfor label in ['low', 'medium', 'high']:\n    submission[label] = y_final[:, labels_interesting_level[label]]\n# write the dataframe to file\nsubmission.to_csv(\"late_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:38:45.369672Z","iopub.execute_input":"2022-03-14T21:38:45.369918Z","iopub.status.idle":"2022-03-14T21:38:45.760448Z","shell.execute_reply.started":"2022-03-14T21:38:45.369889Z","shell.execute_reply":"2022-03-14T21:38:45.759673Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}